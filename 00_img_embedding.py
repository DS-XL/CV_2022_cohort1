# -*- coding: utf-8 -*-
"""img_embedding.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LvU_45U3dn6XFHf8daOHVUyJ7W44GRKo
"""

import os
import sys
from tqdm import tqdm

import numpy as np
import pandas as pd

import torch
import torchvision.transforms.functional as F
import torchvision.transforms as T
import torchvision.models as M
from PIL import Image

import cv2

sys.path.append('..')

"""config"""

# working directory
root_path = os.path.abspath(os.path.dirname('/content/drive/MyDrive/OneCareer/CV Advance/'))
os.chdir(root_path)
# data directory
data_folder = os.path.join(root_path, 'Data/Marketing Text Generation')
img_folders = [os.path.join(data_folder, path) for path in os.listdir(data_folder) if path.isdigit()]

# gpu or cpu (gpu oriented cause faster on google colab)
is_cuda = True
device = torch.device('cuda') if is_cuda else torch.device('cpu')

"""data_utils"""

def write_samples(samples, file_path, opt='w'):
    """Write the samples into a file.

    Args:
        samples (list): The list of samples to write.
        file_path (str): The path of file to write.
        opt (str, optional): The "mode" parameter in open(). Defaults to 'w'.
    """
    with open(file_path, opt, encoding='utf8') as file:
        for line in samples:
            file.write(line)
            file.write('\n')

"""model"""

def get_img_embedding1 (img, resnet, is_cuda=is_cuda):
    """transform img to vec.

    Args:
        img: image file.
        resnet: resnet model.
    """
    transform1 = T.Compose([T.ToTensor()])  # transforms.ToTensor()

    img = Image.open(img)
    img = img.convert("RGB") # Convert images to 3 channels
    img1 = transform1(img)

    if is_cuda == True:
      x = torch.autograd.Variable(torch.unsqueeze(img1, dim=0).float(), requires_grad=False)
      y = resnet(x.to(device))

      y = y.data.cpu().numpy() # move inputs on cpu before to_numpy
      y = y.tolist()
    
    else:
      x = torch.autograd.Variable(torch.unsqueeze(img1, dim=0).float(), requires_grad=False)
      y = resnet(x)
      y = y.data.numpy()
      y = y.tolist()

    return y

"""Sourceï¼šhttps://zhuanlan.zhihu.com/p/27382990

Execution
"""

# Using Resnet50 OR Resnet101 to extract overall image features

#resnet = M.resnet50(pretrained=True).to(device)
#img_embedding_path = os.path.join(root_path, 'files/img_embedding - ResNet50.txt') # image embedding save path

resnet = M.resnet101(pretrained=True).to(device)
img_embedding_path = os.path.join(root_path, 'files/img_embedding - ResNet101.txt') # image embedding save path

mappings = []

for img_folder in tqdm(img_folders):
    print('folder: ', img_folder)
    img_files = os.listdir(img_folder)
    count = 0
    for img_file in tqdm(img_files):
        img = os.path.join(img_folder, img_file)
        img_vec = get_img_embedding1(img, resnet)
        mapping = img_file + '\t' + ' '.join(map(lambda x: str(x), img_vec))
        mappings.append(mapping)
    write_samples(mappings, img_embedding_path, opt='a')