# -*- coding: utf-8 -*-
"""00_exploratory_data_analysis_for_data.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_iloscvJ4pyVPQ_g4AfObopYyBurB-Dx

<h1> EDA for text generation project </h1>
<li> EDA of the file "Marketing Text Generation/clothing_1w_.json"

## Data Loading
"""

# environment set up
from google.colab import drive
drive.mount('/content/drive')

# import libraries
import numpy as np
import pandas as pd
from tqdm import tqdm
import json
import seaborn as sns
import spacy
import wordcloud
import matplotlib.pyplot as plt
import plotly.express as px
import warnings
warnings.filterwarnings("ignore")
import jieba  
import codecs 
from wordcloud import WordCloud, STOPWORDS

# helper 
if_use_clothing_1 = True
if_use_clothing_2 = False
if_use_clothing_3 = False

name = ''
if if_use_clothing_1:
  name = 'clothing_1w_1'
if if_use_clothing_2:
  name = 'clothing_1w_2'
if if_use_clothing_3:
  name = 'clothing_1w_3'

save_file_path = '/content/drive/MyDrive/Marketing Text Generation/'+ name +'.csv'

# Commented out IPython magic to ensure Python compatibility.
# # load the json data
# %%time
# if if_use_clothing_1:
#   with open(r'/content/drive/MyDrive/Marketing Text Generation/clothing_1w_1.json', 'r') as f:
#     text_data = json.load(f)
# elif if_use_clothing_2:
#   with open(r'/content/drive/MyDrive/Marketing Text Generation/clothing_1w_2.json', 'r') as f:
#     text_data = json.load(f)
# else:
#   with open(r'/content/drive/MyDrive/Marketing Text Generation/clothing_1w_3.json', 'r') as f:
#     text_data = json.load(f)
#

# tranform the json data into pandas dataframe
clothes = pd.DataFrame.from_dict({i: text_data[i] 
                                  for i in text_data.keys()},
                                  orient='index').reset_index()

# change the columns name
clothes.columns = ['item_id', 'description', 'category', 'keywords']

clothes['desc'] = clothes['description'].apply(lambda x: ','.join(map(str, x)))

# remove white space between Chinese characters
import re

def clean_space(text):
    match_regex = re.compile(u'[\u4e00-\u9fa5。\.,，:：《》、\(\)（）]{1} +(?<![a-zA-Z])|\d+ +| +\d+|[a-z A-Z]+')
    should_replace_list = match_regex.findall(text)
    order_replace_list = sorted(should_replace_list,key=lambda i:len(i),reverse=True)
    for i in order_replace_list:
        if i == u' ':
            continue
        new_i = i.strip()
        text = text.replace(i,new_i)
    return text

clothes['desc'] = clothes['desc'].apply(clean_space)
clothes.head()

# save data to csv file
clothes.to_csv(save_file_path,index=False)

"""## EDA"""

# create new column 'desc_len' to show the length of each description text
# visualize the result
# we can see that the count of length of description text is imbalance. 
clothes['desc_len'] = clothes['desc'].apply(len)
fig = px.histogram(data_frame= clothes, x = "desc_len",  marginal="violin",nbins = 400 )
fig.update_layout(template="plotly_white")
fig.show()

# segment words to extract keywords for word cloud generation
def segment_words(data_content):
  segment = []
  for content in data_content:
    try:
        segs = jieba.lcut(content)
        for seg in segs:
            if len(seg)>1 and seg != '\r\n':
                segment.append(seg)
    except:
        continue
  return segment

# generate wordcloud
def wordcloud_gen(segment):
  words_df = pd.DataFrame({'segment':segment})
  stopwords = pd.read_csv("https://github.com/elephantnose/characters/blob/3ebf72a0766883954ac6a3f4ab6e67f59c999f63/stop_words",index_col=False,quoting=3,sep='\t',names=['stopword'])
  words_df = words_df[~words_df['segment'].isin(stopwords['stopword'])] #去除停止词
  data = words_df['segment'].value_counts().to_dict()
  wc = WordCloud(
       background_color="white", 
       max_words=2000, contour_width=3, 
       contour_color='steelblue',
       scale=5,
       font_path='/content/drive/MyDrive/Marketing Text Generation/Kaiw5-gb5-2.ttf').generate_from_frequencies(data)
  plt.figure( figsize=(20,10) )
  plt.imshow(wc)
  plt.show()
  #wc.to_file(/content/drive/MyDrive/Marketing Text Generation/image.png')

# generate wordcloud plot seperately for both description text and keywords
desc_content = clothes['desc'].values.tolist()
keyword_content = clothes['keywords'].values.tolist()
segment_desc = segment_words(desc_content)
segment_keyword = segment_words(keyword_content)

# word cloud plot for 'desc' column
wordcloud_gen(segment_desc)

# wordcloud plot for keyword column
wordcloud_gen(segment_keyword)

